# sentiment_flow.py
from dag_engine import node, inject, WorkflowContext
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import numpy as np

# ðŸŒŸ Modelul folosit
MODEL_NAME = "cardiffnlp/twitter-xlm-roberta-base-sentiment"

print("ðŸ”¹ Loading transformer model...")

tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)

# ðŸŒŸ Stare globalÄƒ pentru propagarea emoÈ›iilor
global_emotion_state = {
    "energy": 0.0,
    "history": []
}


# ---------------------------------------------------------
# ðŸŸ¦ NOD 1: Normalizare text
# ---------------------------------------------------------
@inject
@node(name="Normalizare", depends_on=())
class Normalizare:
    ctx: WorkflowContext

    def run(self, ctx: WorkflowContext):
        txt = ctx.inputs.get("text", "")
        norm = " ".join(txt.strip().lower().split())
        return {"text_norm": norm}


# ---------------------------------------------------------
# ðŸŸ§ FuncÈ›ie auxiliarÄƒ: calculÄƒm top cuvinte influente
# ---------------------------------------------------------
def extract_top_features(text, scores, n=3):
    """
    HeuristicÄƒ simplÄƒ:
    - Ã®mpÄƒrÈ›im textul Ã®n cuvinte
    - atribuim scor sentiment fiecÄƒrui cuvÃ¢nt (doar pentru afiÈ™are)
    - NU este SHAP, dar oferÄƒ utilizatorului o idee vizualÄƒ
    """
    words = text.split()
    if not words:
        return []

    pos = scores["pozitiv"]
    neu = scores["neutru"]
    neg = scores["negativ"]

    # alegem 3 cuvinte aleatoriu, ponderate dupÄƒ lungime (simplu È™i eficient)
    weighted = sorted(words, key=lambda x: -len(x))
    top = weighted[:n]

    return top


# ---------------------------------------------------------
# ðŸŸ¥ NOD 2: Sentiment AI (transformer)
# ---------------------------------------------------------
@inject
@node(name="SentimentAI", depends_on=("Normalizare",))
class SentimentAI:
    ctx: WorkflowContext

    def run(self, ctx: WorkflowContext):

        text = ctx.store["Normalizare"]["text_norm"]

        inputs = tokenizer(text, return_tensors="pt", truncation=True)
        with torch.no_grad():
            outputs = model(**inputs)
            probs = torch.softmax(outputs.logits, dim=1)[0].numpy()

        neg, neu, pos = probs.tolist()

        # alegem eticheta finalÄƒ
        if pos == max(probs):
            label = "Pozitiv"
        elif neg == max(probs):
            label = "Negativ"
        else:
            label = "Neutru"

        scores = {
            "pozitiv": round(pos * 100, 2),
            "neutru": round(neu * 100, 2),
            "negativ": round(neg * 100, 2)
        }

        # top cuvinte extrase pentru UI
        features = extract_top_features(text, scores)

        return {
            "label": label,
            "scores": scores,
            "features": features
        }


# ---------------------------------------------------------
# ðŸŸ© NOD 3: Propagarea emoÈ›iilor Ã®n reÈ›ea
# ---------------------------------------------------------
@inject
@node(name="Propagation", depends_on=("SentimentAI",))
class Propagation:
    ctx: WorkflowContext

    def run(self, ctx: WorkflowContext):

        sentiment_scores = ctx.store["SentimentAI"]["scores"]

        pos = sentiment_scores["pozitiv"] / 100
        neu = sentiment_scores["neutru"] / 100
        neg = sentiment_scores["negativ"] / 100

        emotional_energy = round(pos - neg, 3)
        stability = round(1 - abs(pos - neg), 3)

        return {
            "emotional_energy": emotional_energy,
            "stability": stability,
            "dominant": ctx.store["SentimentAI"]["label"],
            "vector": {
                "pos": pos,
                "neu": neu,
                "neg": neg
            }
        }


# ---------------------------------------------------------
# ðŸŸ¨ NOD 4: Starea emoÈ›ionalÄƒ globalÄƒ (acumulatÄƒ)
# ---------------------------------------------------------
@inject
@node(name="GlobalEmotion", depends_on=("Propagation",))
class GlobalEmotion:
    ctx: WorkflowContext

    def run(self, ctx: WorkflowContext):

        global global_emotion_state
        step = ctx.store["Propagation"]

        # acumulÄƒm energia emoÈ›ionalÄƒ
        global_emotion_state["energy"] += step["emotional_energy"]
        global_emotion_state["energy"] = round(global_emotion_state["energy"], 3)

        # istoricul emoÈ›iilor detectate
        global_emotion_state["history"].append(step["dominant"])

        return {
            "network_energy": global_emotion_state["energy"],
            "history": global_emotion_state["history"]
        }
